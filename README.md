# AI PDF Voice Assistant v2.0

A **production-ready** FastAPI-based PDF Question-Answering system with authentication, chat history, multi-PDF management, and voice I/O.

## Features

| Feature | Description |
|---|---|
| ğŸ” **Authentication** | JWT-based register/login with bcrypt password hashing |
| ğŸ’¬ **Text & Voice Chat** | Ask questions via text or voice recording |
| ğŸ“„ **Multi-PDF RAG** | Upload multiple PDFs â€” answers are sourced from your PDF library |
| ğŸ§  **Hybrid Answers** | PDF-context first, fallback to general LLM knowledge |
| ğŸ“Š **Source Badges** | Each answer shows whether it came from PDF or general knowledge |
| ğŸ—‚ï¸ **Chat History** | Persistent sessions saved to SQLite, accessible from the sidebar |
| ğŸ¤ **Whisper STT** | OpenAI Whisper (small model) for high-accuracy voice recognition |
| ğŸ”Š **TTS Output** | Google TTS for voice answers, with per-message replay |
| ğŸ“± **Responsive UI** | Full-screen dark glassmorphism SPA, works on mobile & desktop |

## Architecture

```
app.py                    â† FastAPI entry point
config.py                 â† Centralized settings (env-var overrides)
database.py               â† SQLite + SQLAlchemy
models.py                 â† User, ChatSession, Message, PDFDocument
auth.py                   â† JWT + bcrypt authentication
routers/
  auth_router.py          â† Register, Login, Me
  chat_router.py          â† Text chat, Voice chat, Sessions CRUD
  pdf_router.py           â† Upload, List, Delete PDFs
services/
  llm_service.py          â† RAG pipeline, per-user FAISS retriever
stt.py                    â† Speech-to-Text (Whisper)
tts.py                    â† Text-to-Speech (gTTS)
llm.html                  â† Full-screen SPA frontend
```

## Setup

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Start LM Studio
# Set Base URL â†’ http://localhost:1234/v1

# 3. Run the server
uvicorn app:app --reload

# 4. Open browser
# http://127.0.0.1:8000
```

## Tech Stack

- **Backend**: FastAPI, SQLAlchemy, LangChain, FAISS, Whisper, gTTS
- **Auth**: JWT (python-jose), bcrypt (passlib)
- **LLM**: LM Studio (TinyLlama 1.1B) via OpenAI-compatible API
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **Frontend**: Pure HTML/CSS/JS SPA (no frameworks)
- **Database**: SQLite (zero config)
